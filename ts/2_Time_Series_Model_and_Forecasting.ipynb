{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S5YL-4ppLj1L"
      },
      "source": [
        "## Time series and forecasting models\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "8IQnl3ehMfSs"
      },
      "source": [
        "### Time series as stochastic processes\n",
        "* $X(t)$ or $X_t$, $t =1, 2, \\dots$ (random variables)\n",
        "* *Mean*. $\\mu(t) = E [X(t)] $\n",
        "* *Variance*. $\\sigma^2(t) = {\\rm Var}[X(t)]$\n",
        "* *Autocovariance*. $\\gamma(t_1, t_2) = E\\{[X(t_1) - \\mu(t_1)][X(t_2) - \\mu(t_2)]\\}$\n",
        "* A time series is called (weakly) stationary if its mean is a constant and autocovariance function depends only on the lag $t_2-t_1$.\n",
        "* It follows its variance is also a constant (corresponding to autocovariance for lag 0).  \n",
        "* *Autocorrelation* at lag $\\tau$: $\\rho(\\tau) = {\\rm corr}(X_t, X_{t+\\tau})$\n",
        "* Sample mean, sample autocovariance, sample autorrelation: \\\\\n",
        "Use sample average to replace the expectation in the definition"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xc9vV_IBQKCB"
      },
      "source": [
        "### White noise processes\n",
        "* $Z_1, Z_2, \\dots$, mutually independent and identically distributed\n",
        "* mean 0, variance $\\sigma_Z^2$\n",
        "* autocorrelation at lag $k$:\n",
        "$\\rho(k) = 1$ if $k=0$, $\\rho(k)=0$ otherwise\n",
        "* sometimes weaker assumption is used: \\\\\n",
        "$Z_1, Z_2, \\dots$, mutually uncorrelated \n",
        "* it is the simplest stationary process\n",
        "* it is used as building blocks for more complicated models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Io839kYfmrOO",
        "outputId": "7fd1c1db-e521-4236-93c0-8f37dc709fe5"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
        "from statsmodels.tsa.arima_process import arma_generate_sample\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!pip install statsmodels\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R9Kiw7VsLPN2"
      },
      "source": [
        "**Example**: Generate a white noise process and draw a time series plot of the process. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        },
        "id": "hotpwZoKTMc7",
        "outputId": "cbcbe702-3088-4bc5-daae-44bf2b028302"
      },
      "outputs": [],
      "source": [
        "# seed random number generator\n",
        "np.random.seed(42)\n",
        "\n",
        "# create white noise array\n",
        "white_noise_array = np.random.normal(loc=0, scale=1, size= 200)\n",
        "\n",
        "# draw a time series plot\n",
        "plt.figure(figsize=(10,2))\n",
        "plt.plot(white_noise_array)\n",
        "plt.title('White Noise Process')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2nVyeC-Mit_f"
      },
      "outputs": [],
      "source": [
        "mu, sigma = 0, 0.1 # mean and standard deviation\n",
        "s = np.random.normal(mu, sigma, 1000)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xmroqxwhivyq",
        "outputId": "ff93fb03-d78a-4a0d-917a-f471347674af"
      },
      "outputs": [],
      "source": [
        "abs(sigma - np.std(s, ddof=1))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vA58Dw5gTHE9"
      },
      "source": [
        "### Random walks\n",
        "* $\\{Z_t, t= 1, 2, \\dots \\}$ is a white noise process with mean $\\mu$ and variance $\\sigma_Z^2$\n",
        "* $\\{X_t, t=1, 2, \\dots \\}$ is a random walk if \\\\\n",
        "$$X_t = X_{t-1} + Z_t$$\n",
        "* the process is customarily started at zero when $t=0$, so that $X_1 = Z_1$\n",
        "* $X_t = \\sum_{i=1}^t Z_i$\n",
        "* $E(X_t) = t\\mu$, ${\\rm Var}(X_t) = t\\sigma_Z^2$, both changing with $t$\n",
        "* a random walk is non-stationary\n",
        "* the first difference of a random walk is a white noise, which is stationary \\\\\n",
        "$$X_t - X_{t-1} = Z_t$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1z7qWAPiFnI3"
      },
      "source": [
        "**Example**: Generate a random walk process and draw a time series plot. Compare with the time series plot of the first difference of random walk.\n",
        "\n",
        "Two methods for generating random walk process are presented. \n",
        "1. Use a for loop, according to the model equation of the white noise process.\n",
        "2. Take the cumulative sum of the white noise process. (The looping operation is implicit.)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FQnyEXaSl4lE"
      },
      "outputs": [],
      "source": [
        "# Method 1: Generate a random walk process according to the definition X_t = X_{t-1} + Z_t using a for loop\n",
        "## seed random generator\n",
        "np.random.seed(42)\n",
        "\n",
        "## create random walk process\n",
        "random_walk_array = np.zeros(200)\n",
        "random_walk_array[0] = np.random.normal()\n",
        "for i in range(1, 200):\n",
        "  random_walk_array[i] = random_walk_array[i-1] + np.random.normal()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lmjEF97jBrGu"
      },
      "outputs": [],
      "source": [
        "# Method 2: An easier way to generate a random walk process by taking cumulative sum of the white noise\n",
        "# We use white_noise_array enerated in the previous example. (We need to run the code chunk for generating the white noise before running this trunk.)\n",
        "random_walk_array = np.cumsum(white_noise_array)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        },
        "id": "V5rPnbpMDLxm",
        "outputId": "65b29176-184d-4fe0-ec0c-5f513c98b23f"
      },
      "outputs": [],
      "source": [
        "# Visualization\n",
        "plt.figure(figsize=(10,2))\n",
        "plt.plot(random_walk_array)\n",
        "plt.title('Random Walk Process')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6MizFBctmK4h"
      },
      "source": [
        "### Moving Average processes\n",
        "* $\\{Z_t, t=1, 2, \\dots\\}$ is a white noise process\n",
        "* $\\{X_t, t=1, 2, \\dots\\}$ is a moving average process of order $q$, MA($q$), if\n",
        "$$X_t = \\beta_0 Z_t  + \\beta_1 Z_{t-1} + \\dots + \\beta_q Z_{t-q}$$\n",
        "where $\\beta_i$ are constants.\n",
        "* Usually $Z$s are scaled so that $\\beta_0 =1$.\n",
        "* $E(X_t) =0$\n",
        "* ${\\rm Var} (X_t) = \\sigma_Z^2 \\sum_{i=1}^q \\beta_i^2$.\n",
        "* Autocorrelation function (ACF)\n",
        "$$ \\rho(k) = {\\rm corr} (X_t, X_{t+k}) = \\begin{cases} 0  & k >q \\\\ \n",
        " \\sum_{i=1}^{q-k} \\beta_i\\beta_{i+1}/\\sum_{i=1}^q \\beta_i^2 & k =0, \\dots, q\\\\\n",
        "\\rho(-k) & k<0 \\end{cases} $$\n",
        "* MA($q$) is a stationary process (because the above quantities do not depend on $t$).\n",
        "* The autocorrelation \"cuts off\" at lag $q$. -- *This property can be used to identify the order of a MA process.*\n",
        "* Sample autocorrelation will not \"cuts off\" exactly becaues of randomness"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7GPhey-pQ2Ji"
      },
      "source": [
        "**Example**: Generate a MA($q$) process with $q = 2$ and draw a time series plot of the process. \n",
        "\n",
        "Two methods for generating a MA($2$) process are presented. \n",
        "1. The MA($2$) process is generated according to its defining equation\n",
        "$$\n",
        "X_t = \\beta_0Z_t + \\beta_1 Z_{t-1} +\\beta_2 Z_{t-2} \n",
        "$$\n",
        "where $\\beta_0 = 1, \\beta_1 = 0.8$ and $\\beta_3 = 0.5$. \n",
        "2. The MA($2$) process is generated using `arma_generate_sample` function in the module `arma_process`. The definition of ARMA model and the relation between ARMA and MA model will be introduced later. \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hkLOaU74Bl1s"
      },
      "outputs": [],
      "source": [
        "# Method 1: Generate a MA(2) process according to its model equation.\n",
        "## seed random generator\n",
        "np.random.seed(42)\n",
        "##  create ma(2) array\n",
        "order_ma = 2 # order\n",
        "ma_coef = [1.0, 0.8, 0.5] # MA coefficient [beta_0, beta_1, beta_2]\n",
        "## create random noise array\n",
        "white_noise = np.random.normal(size=1000)\n",
        "## initialization\n",
        "ma_array = np.zeros(1000)\n",
        "ma_array[0:2] = [0,0]\n",
        "## assignment\n",
        "for i in range(2, 1000):\n",
        "    ma_array[i] = ma_coef[0] * white_noise[i] + ma_coef[1] * white_noise[i-1] + ma_coef[2] * white_noise[i-2]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PvT1mU8QCpdC"
      },
      "outputs": [],
      "source": [
        "# Method 2: Generate a MA(2) process using arma_generate_sample function\n",
        "\n",
        "from statsmodels.tsa.arima_process import arma_generate_sample\n",
        "\n",
        "np.random.seed(42)\n",
        "ma_coef = [1.0,0.8,0.5]\n",
        "ma_array = arma_generate_sample(ar = [1.0],ma = ma_coef,nsample =  1000)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 437
        },
        "id": "UCA16rbEC50G",
        "outputId": "12ee90e9-f199-4a22-d287-dc2e4e80aed8"
      },
      "outputs": [],
      "source": [
        "#  Visualization\n",
        "ma_array_300 = ma_array[700:1000]\n",
        "plt.figure(figsize=(10,2))\n",
        "plt.plot(ma_array_300)\n",
        "plt.title('Moving Average Process')\n",
        "plt.show()\n",
        "## Check the ACF plot\n",
        "plot_acf(pd.DataFrame(ma_array_300))\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "afhpBFpjuohy"
      },
      "source": [
        "The first two autocorrelation coefficients are significantly different from zero, suggesting an MA(2) process."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SDkHBJFur-sF"
      },
      "source": [
        "### Autoregressive processes\n",
        "* $\\{Z_t, t=1, 2, \\dots\\}$ is a white noise process\n",
        "* $\\{X_t, t=1, 2, \\dots\\}$ is an autoregressive process of order $p$, AR($p$), if\n",
        "$$X_t = \\alpha_1 X_{t-1} + \\dots \\alpha_p X_{t-p} + Z_{t}$$\n",
        "where $\\alpha_i$ are constants.\n",
        "* This is link a multiple regression model, but $X_t$ is regressed on past values of $X_t$. -- This explains the prefix \"auto\".\n",
        "* $E(X_t)=0$\n",
        "* It is stationary under some conditions on the coefficients $\\alpha_i$s.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tWKSDsY_jBy3"
      },
      "source": [
        "**Example**: Generate a AR(1) process with multiple choices of $\\alpha$ and draw a time series plot of the process. \n",
        "\n",
        "Two methods to generate AR($1$) process are presented. \n",
        "1. The AR($1$) process is generated according to the definition such that\n",
        "$$\n",
        "X_t = Z_t + \\alpha X_{t-1} \n",
        "$$\n",
        "2. The AR($1$) process is generated using `arma_generate_sample` function in the module `arma_process`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UbmKHy6W1JEH"
      },
      "outputs": [],
      "source": [
        "# Method 1: Generate the AR(1) process according to its definition\n",
        "def Autoregressive(alpha, seed=42):\n",
        "   # seed random generator\n",
        "    np.random.seed(seed)\n",
        "   # create AR(1) array\n",
        "    ar = np.zeros(100)\n",
        "    ar[0] = np.random.normal(loc=0, scale=1.0/(1-alpha**2), size=1)\n",
        "    ## assignment\n",
        "    for i in range(1, 100):\n",
        "        ar[i] = alpha * ar[i-1] + np.random.normal(size=1)\n",
        "    return ar\n",
        "\n",
        "auto_reg1 = Autoregressive(0.8)\n",
        "auto_reg2 = Autoregressive(0.3)\n",
        "auto_reg3 = Autoregressive(-0.8)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LIKbbN-zDglO"
      },
      "outputs": [],
      "source": [
        "# Method 2: Generate the AR(1) using the arma_generate_sample function\n",
        "\n",
        "from statsmodels.tsa.arima_process import arma_generate_sample\n",
        "\n",
        "ar_coef = [1.0, -0.8] # Note we need to add a negative sign in front of the AR coefficient.\n",
        "ma_coef = [1.0]\n",
        "auto_reg = arma_generate_sample(ar = ar_coef, ma = ma_coef, nsample =  100)\n",
        "\n",
        "# If we need to repeat the process for different values of the AR coefficient, it is better to write a python function.\n",
        "\n",
        "def Autoregressive(alpha, seed = 42):\n",
        "  np.random.seed(seed)\n",
        "  ar_coef = [1.0, -1.0*alpha]\n",
        "  ma_coef = [1.0]\n",
        "  ar_array = arma_generate_sample(ar = ar_coef,ma = ma_coef,nsample =  100)\n",
        "  return ar_array\n",
        "\n",
        "auto_reg1 = Autoregressive(0.8)\n",
        "auto_reg2 = Autoregressive(0.3)\n",
        "auto_reg3 = Autoregressive(-0.8)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 163
        },
        "id": "kz74rs2sDlxf",
        "outputId": "2927b89e-8760-4968-cea3-97d39da1b9ab"
      },
      "outputs": [],
      "source": [
        "# Visualization of the time series\n",
        "\n",
        "plt.figure(figsize=(18,2))\n",
        "plt.subplot(131)\n",
        "plt.plot(auto_reg1)\n",
        "plt.title('Auto_reg coefficient=0.8')\n",
        "plt.subplot(132)\n",
        "plt.plot(auto_reg2)\n",
        "plt.title('Auto_reg coefficient=0.3')\n",
        "plt.subplot(133)\n",
        "plt.plot(auto_reg3)\n",
        "plt.title('Auto_reg coefficient=-0.8')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "id": "er8nH6op5Cmu",
        "outputId": "01965809-1126-4cdb-a25d-2a9e6fe1ca60"
      },
      "outputs": [],
      "source": [
        "# Plots of sample autocorrelation function. We need to use the Python module matplotlib.gridspect to arrange multiplots.\n",
        "import matplotlib.gridspec as gridspec\n",
        "\n",
        "fig = plt.figure(tight_layout = True, figsize = (12, 4))\n",
        "gs = gridspec.GridSpec(1, 3)\n",
        "ax = fig.add_subplot(gs[0,0])\n",
        "plot_acf(pd.DataFrame(auto_reg1), ax=ax, title='Autocorrelation case: alpha=0.8')\n",
        "ax = fig.add_subplot(gs[0,1])\n",
        "plot_acf(pd.DataFrame(auto_reg2), ax=ax, title='Autocorrelation case: alpha=0.3')\n",
        "ax = fig.add_subplot(gs[0,2])\n",
        "plot_acf(pd.DataFrame(auto_reg3), ax=ax, title='Autocorrelation case: alpha=-0.8')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u0bjwM4V4XRC"
      },
      "source": [
        "\n",
        "### Some theory of AR(1) processes\n",
        "* $X_t = \\alpha X_{t-1} + Z_t$\n",
        "* Backward shift operator $B$: $B X_t = X_{t-1}$.\n",
        "* AR(1) model can be rewritten as $(1-\\alpha B) X_t = Z_t$\n",
        "* MA($\\infty$) representation\n",
        "$$ \\begin{eqnarray*} X_t &=& Z_t/ (1-\\alpha B) \\\\ \n",
        "&=& (1 + \\alpha B + \\alpha^2 B^2 + \\dots) Z_t\\\\\n",
        "&=& Z_t + \\alpha Z_{t-1} + \\alpha^2 Z_{t-2} + \\dots \\end{eqnarray*} $$\n",
        "* This representation can be used to derive the autocorrelation function\n",
        "$$\\rho(k) = {\\rm corr}(X_t, X_{t+k}) = \\alpha^k, \\quad k = 0, 1, 2, \\dots $$\n",
        "* Need $|\\alpha| < 1 $ for the process to be stationary.\n",
        "* If $\\alpha$ is close to $0$, the autocorrelaton decays quickly to 0.\n",
        "* If $\\alpha$ is negative, the autocorrelaton alternates between positive and negative values."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "auXL_CQzNrmS"
      },
      "source": [
        "### Indentify the order of an AR process by inspecting the Partial Autocorrelation (PACF) plot.\n",
        "\n",
        "Partial autocorrelation can be imagined as the correlation between the series and its lag, after excluding the contributions from the intermediate lags. So, PACF sort of conveys the pure correlation between a lag and the series. That way, you will know if that lag is needed in the AR term or not.\n",
        "\n",
        "So what is the formula for PACF mathematically?\n",
        "\n",
        "Partial autocorrelation of lag k of the series $\\{X_t\\} $ is the coefficient $\\alpha_k$ in the following autoregression equation:\n",
        "\n",
        "$$X_t = \\alpha_0 + \\alpha_1 X_{t-1} + \\alpha_2 X_{t-2} + \\dots \\alpha_k X_{t-k} + Z_t$$\n",
        "\n",
        "How to find the number of AR terms?\n",
        "\n",
        "Any autocorrelation in a stationarized series can be rectified by adding enough AR terms. So, we initially take the order of AR term to be equal to as many lags that crosses the significance limit in the PACF plot.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lxk2FV7R804r"
      },
      "source": [
        "### Mixed ARMA models\n",
        "* A mixed autoregressive/moving-average process containing $p$ AR terms and $q$ MA terms is called an ARMA process of order $(p,q)$.\n",
        "* Its equation\n",
        "$$ X_t = \\alpha_1 X_{t-1} + \\dots + \\alpha_p X_{t-p} + Z_t + \\beta_1 Z_{t-1} + \\dots + \\beta_q Z_{t-q}$$\n",
        "* Define two polynomials \n",
        "$$\n",
        "\\begin{eqnarray*} \n",
        "\\phi(B) & = & 1 -\\alpha_1 B - \\dots - \\alpha_p B^p\\\\\n",
        "\\theta(B) & = & 1 + \\beta_1 B + \\dots + \\beta_q B^q\n",
        "\\end{eqnarray*}\n",
        "$$\n",
        "* If $B$ is the backward shift operator, ARMA model can be written as\n",
        "$$ \\phi(B) X_t = \\theta(B) Z_t\n",
        "$$\n",
        "* The process is stationary under certain conditions on the coefficients.\n",
        "* Condition: The (complex) roots of $\\phi(B)$ =0 and $\\theta(B) = 0$ lie outside the unit circle.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f1hQBiZWvMLP"
      },
      "source": [
        "**Example**: Generate a sample path for the following ARMA(2,1) process and draw a time series plot.\n",
        "$$\n",
        "X_t = \\frac{5}{6}X_{t-1}-\\frac{1}{6}X_{t-2}+Z_t + \\frac{1}{2}Z_{t-1}\n",
        "$$\n",
        "The equation can also be written as\n",
        "$$\n",
        "X_t - \\frac{5}{6}X_{t-1} + \\frac{1}{6}X_{t-2} = Z_t + \\frac{1}{2}Z_{t-1}\n",
        "$$\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WLu25F2XAo9P"
      },
      "outputs": [],
      "source": [
        "from statsmodels.tsa.arima_process import arma_generate_sample\n",
        "\n",
        "# seed random generator\n",
        "np.random.seed(192)\n",
        "\n",
        "# Generate arma(2,1) array using Python arma_generate_sample function \n",
        "ar_coef = [1, -5/6, 1/6] # The coefficient for autoregressive lag polynomial phi(B), including zero lag\n",
        "ma_coef = [1, 1/2] # The coefficient for moving-average lag polynomial theta(B), including zero lag\n",
        "my_arma_array = arma_generate_sample(ar_coef, ma_coef, 250) #sample size = 250"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        },
        "id": "VEnnZEy1ER2n",
        "outputId": "46c43ab4-25eb-4cb9-d598-eb56d9ebca69"
      },
      "outputs": [],
      "source": [
        "# Visualization\n",
        "plt.figure(figsize=(12,2))\n",
        "plt.plot(my_arma_array)\n",
        "plt.title('ARMA(2,1) process')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "id": "YOzrGXuYJR48",
        "outputId": "897b093f-760f-4c23-cae7-67f8d749fca0"
      },
      "outputs": [],
      "source": [
        "## ACF and PACF plot\n",
        "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
        "import matplotlib.gridspec as gridspec\n",
        "\n",
        "fig = plt.figure(tight_layout = True, figsize = (12, 4))\n",
        "gs = gridspec.GridSpec(1, 2)\n",
        "ax = fig.add_subplot(gs[0,0])\n",
        "plot_acf(my_arma_array,title='ACF of ARMA(2,1)', ax = ax)\n",
        "ax = fig.add_subplot(gs[0,1])\n",
        "plot_pacf(my_arma_array,title='PACF of ARMA(2,1)',ax = ax)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8bBnT-lhEroY"
      },
      "source": [
        "We observe there are some significant ACF coefficients and PACF coefficients."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Oi7dHW6F_LGn"
      },
      "source": [
        "### Why ARMA models?\n",
        "* A stationary time series may often be adequately modelling by an ARMA model involving fewer parameters than a pure MA or AR process by itself.\n",
        "* This is calle the **Principle of Parsimony.**\n",
        "* We want to find a model with as few parameters as possible, but which gives an adequate representation of the data at hand."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lAG5gp8RA9G_"
      },
      "source": [
        "### Integrated ARMA (ARIMA) model\n",
        "* In practice, many time series are non-stationary.\n",
        "* Differencing the series can remove the non-stationary sources of variation.\n",
        "* First difference: $\\Delta X_t = X_t - X_{t-1} = (1-B) X_t$\n",
        "* Second difference: $\\Delta^2 X_t = \\Delta X_t - \\Delta X_{t-1} = (1-B^2) X_t$\n",
        "* $d$-th difference: $W_t = \\Delta^d X_t = (1-B)^d X_t$ \n",
        "* $W_t$ is ARMA$(p,q)$:\n",
        "$$ W_t = \\alpha_1 W_{t-1} + \\dots + \\alpha_p W_{t-p} + Z_t + \\beta_1 Z_{t-1} + \\dots + \\beta_q Z_{t-1}$$\n",
        "* $X_t$ is called an ARIMA process of order $(p,d,q)$ -- autoregressive integrated moving average\n",
        "* $X_t$ is not stationary. Its $d$-th difference $W_t$ is stationary.\n",
        "* First differencing is often found to be adequate in pratice.\n",
        "* The random walk is ARIMA (0,1,0). --It is white noise after taking first diference."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j6otu_bG0R-l"
      },
      "source": [
        "**Example**: Generate an ARIMA(2,1,1) process based on `my_arma_array` (ARMA(2,1)) created in the previous example and draw the time series plot of the process. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "id": "VgkMNmhPAqcr",
        "outputId": "44281362-b282-4e90-8858-7257900cf3e1"
      },
      "outputs": [],
      "source": [
        "# Generate a sample path for an ARIMA(2,1,1) process using the sample path of an ARMA(2,1) process\n",
        "# Use cumsum function in numpy\n",
        "my_arima_array = np.cumsum(my_arma_array) \n",
        "\n",
        "# visualization\n",
        "plt.figure(figsize=(12,4))\n",
        "plt.subplot(121)\n",
        "plt.plot(my_arma_array)\n",
        "plt.title('ARMA(2,1) process')\n",
        "plt.subplot(122)\n",
        "plt.plot(my_arima_array)\n",
        "plt.title('ARIMA(2,1,1) process')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XUoJzqfCMtTN"
      },
      "source": [
        "We observe that ARMA(2,1) is stationary; its path varies around its mean. ARIMA(2,1,1) is not stationary; its path shows a trending behavior (called stochastic trend). We can use the KPSS and ADF tests to check the stationarity of a time series."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "LRSxKOTNp7B7"
      },
      "source": [
        "### ADF test\n",
        "\n",
        "The augmented Dickey–Fuller (ADF) statistic, used in the test, is a negative number. The more negative it is, the stronger the rejection of the hypothesis that there is a unit root at some level of confidence\n",
        "\n",
        "ADF test is used to determine the presence of unit root in the series, and hence helps in understand if the series is stationary or not. The null and alternate hypothesis of this test are:\n",
        "\n",
        " * Null Hypothesis: The series has a unit root, or the series is non-stationary.\n",
        "\n",
        "* Alternate Hypothesis: The series has no unit root, or the series is stationary.\n",
        "\n",
        "If the null hypothesis in failed to be rejected, this test may provide evidence that the series is non-stationary."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sWFbP-aVqM7d"
      },
      "outputs": [],
      "source": [
        "# ADF test for checking the stationarity of a time series.\n",
        "from statsmodels.tsa.stattools import adfuller\n",
        "\n",
        "def adf_test(timeseries):\n",
        "    print ('Results of Dickey-Fuller Test:')\n",
        "    dftest = adfuller(timeseries, autolag='AIC')\n",
        "    dfoutput = pd.Series(dftest[0:4], index=['Test Statistic','p-value','#Lags Used','Number of Observations Used'])\n",
        "    for key,value in dftest[4].items():\n",
        "       dfoutput['Critical Value (%s)'%key] = value\n",
        "    print (dfoutput)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tODwOKUNqWXq",
        "outputId": "7bacb97f-3ea3-4ac8-822f-bce70f0b9744"
      },
      "outputs": [],
      "source": [
        "adf_test(my_arima_array)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NcFKqyMtqaa8"
      },
      "source": [
        "p-value is 0.52, which much more than 5% confidence level. The null hypothesis can not be rejected. Hence the series is non-stationary."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "09a_NnZurJga"
      },
      "source": [
        "### KPSS test\n",
        "\n",
        "In econometrics, Kwiatkowski–Phillips–Schmidt–Shin (KPSS) tests are used for testing a null hypothesis that an observable time series is stationary around a deterministic trend (i.e. trend-stationary) against the alternative of a unit root.\n",
        "\n",
        "\n",
        "KPSS is another test for checking the stationarity of a time series. The null and alternate hypothesis for the KPSS test are different from that of the ADF test.\n",
        " * Null Hypothesis: The process is trend stationary.\n",
        " * Alternate Hypothesis: The series has a unit root (series is not stationary)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IDR_z3_2oSxi"
      },
      "outputs": [],
      "source": [
        "# KPSS test for checking the stationarity of a time series.\n",
        "from statsmodels.tsa.stattools import kpss\n",
        "\n",
        "def kpss_test(timeseries):\n",
        "    print ('Results of KPSS Test:')\n",
        "    kpsstest = kpss(timeseries, regression='c')\n",
        "    kpss_output = pd.Series(kpsstest[0:3], index=['Test Statistic','p-value','Lags Used'])\n",
        "    for key,value in kpsstest[3].items():\n",
        "        kpss_output['Critical Value (%s)'%key] = value\n",
        "    print (kpss_output)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jXEZsXdqpZYd",
        "outputId": "fd1e213c-821a-463f-8443-ef8ca9d22cd8"
      },
      "outputs": [],
      "source": [
        "kpss_test(my_arima_array)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ELrOntQerFOt"
      },
      "source": [
        "p-value is 0.01, which less than 5% confidence level. The null hypothesis can be rejected. Hence the series is non-stationary."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 571
        },
        "id": "X6CpTvb3xI9U",
        "outputId": "fa4c0839-b04f-46e7-df16-f44962c988b4"
      },
      "outputs": [],
      "source": [
        "## ACF and PACF plots\n",
        "\n",
        "import matplotlib.gridspec as gridspec\n",
        "\n",
        "fig = plt.figure(tight_layout = True, figsize = (14, 8))\n",
        "gs = gridspec.GridSpec(2, 2)\n",
        "ax = fig.add_subplot(gs[0,0])\n",
        "plot_acf(my_arma_array,title='ACF of ARMA(2,1)', ax = ax)\n",
        "ax = fig.add_subplot(gs[0,1])\n",
        "plot_pacf(pd.DataFrame(my_arma_array),title='PACF of ARMA(2,1)',ax = ax)\n",
        "ax = fig.add_subplot(gs[1,0])\n",
        "plot_acf(my_arima_array,title='ACF of ARIMA(2,1,1)',ax = ax)\n",
        "ax = fig.add_subplot(gs[1,1])\n",
        "plot_pacf(my_arima_array,title='PACF of ARIMA(2,1,1)',ax = ax)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dcc3sQWSF-Qm"
      },
      "source": [
        "The ACF of the ARIMA(2,1,1) process decays very slowly, suggesting it is an integrated process (non-stationary). "
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### The meaning of *p*, *d* and *q* in an ARIMA model \n",
        "\n",
        "*p* is the order of the Auto Regressive (AR) term. It refers to the number of lags of Y to be used as predictors.\n",
        "\n",
        "### The meaning of *d*\n",
        "\n",
        "- The term **Auto Regressive** in ARIMA means it is a linear regression model that uses its own lags as predictors. Linear regression models, as we know, work best when the predictors are not correlated and are independent of each other. So we need to make the time series stationary.\n",
        "\n",
        "- The most common approach to make the series stationary is to difference it. That is, subtract the previous value from the current value. Sometimes, depending on the complexity of the series, more than one differencing may be needed.\n",
        "\n",
        "- The value of d, therefore, is the minimum number of differencing needed to make the series stationary. If the time series is already stationary, then d = 0.\n",
        "\n",
        "#### The meaning of *q*\n",
        "\n",
        "**q** is the order of the Moving Average (MA) term. It refers to the number of lagged forecast errors that should go into the ARIMA Model."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Finding the order of differencing\n",
        "\n",
        "-  An over differenced series may still be stationary, which in turn will affect the model parameters.So we should determine the right order of differencing. \n",
        "-  The right order of differencing is the minimum differencing required to get a near-stationary series which roams around a defined mean and the ACF plot reaches to zero fairly quick.\n",
        "- If the autocorrelations are positive for many number of lags (10 or more), then the series needs further differencing. On the other hand, if the lag 1 autocorrelation itself is too negative, then the series is probably over-differenced.\n",
        "- If we can’t really decide between two orders of differencing, then we go with the order that gives the least standard deviation in the differenced series.\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Finding the order of the AR term (p)\n",
        "\n",
        "- We will find out the required number of AR terms by inspecting the Partial Autocorrelation (PACF) plot.\n",
        "- Partial autocorrelation can be imagined as the correlation between the series and its lag, after excluding the contributions from the intermediate lags. So, PACF sort of conveys the pure correlation between a lag and the series. This way, we will know if that lag is needed in the AR term or not.\n",
        "\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Finding the order of the MA term (q)\n",
        "\n",
        "- We should use the ACF plot for the number of MA terms. An MA term is technically, the error of the lagged forecast.\n",
        "- The ACF tells how many MA terms are required to remove any autocorrelation in the stationarized series."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "Y4wqjGFBLOTZ"
      },
      "source": [
        "\n",
        "### Fitting the ARIMA(p,d,q) model\n",
        "\n",
        "Once you have determined the orders $p,d,q$ in ARIMA model, you can fit the ARIMA model. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T1zSSQsh3YwX"
      },
      "source": [
        "**Example**: Fit a ARIMA model to the `arima_array`(ARIMA(2,1,1)) data that we created in the previous example using `ARIMA()` function. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wpkU8_1dLkrg",
        "outputId": "f8cca067-5889-4c21-b631-d67abc7859fb"
      },
      "outputs": [],
      "source": [
        "from statsmodels.tsa.arima.model import ARIMA\n",
        "\n",
        "# Split sample. Use the first 200 data points in my_arima_array as training data and the last 50 as test data. \n",
        "my_arima_array_train = my_arima_array[:200] \n",
        "my_arima_array_test = my_arima_array[200:]\n",
        "\n",
        "# fit the ARIMA model\n",
        "model = ARIMA(my_arima_array_train,order=(4, 1, 3))\n",
        "#model_fit = model.fit(disp=0)\n",
        "\n",
        "# print the fitting result\n",
        "print(model.fit().summary())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PS9z8OQTOrhI"
      },
      "source": [
        "### Diagnostics\n",
        "After fitting the ARIMA model to data, we can do the following checks on the residuals to see if the fitted model is adequate. \n",
        "\n",
        "1. Plot the residuals to ensure there are no patterns (that is, look for constant mean and variance).\n",
        "\n",
        "2. Series correlation. Plot acf and pacf to ensure there is no significant coefficient. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8ngXrlwI67vV"
      },
      "source": [
        "**Example**: Diagnose the model fitting result. The residuals can be obtained by .resid function. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "id": "UGkQQRJAO0_O",
        "outputId": "7212622e-f8c1-4840-a82c-c285e3f09e0f"
      },
      "outputs": [],
      "source": [
        "residuals = pd.DataFrame(model.fit().resid)\n",
        "\n",
        "# Generate the residual plot\n",
        "fig = plt.figure(tight_layout = True, figsize = (10, 4))\n",
        "gs = gridspec.GridSpec(1, 2)\n",
        "ax = fig.add_subplot(gs[0,0])\n",
        "residuals.plot(title=\"Residuals\",ax=ax, legend=False)\n",
        "ax = fig.add_subplot(gs[0,1])\n",
        "residuals.plot(kind='kde',title='Density',ax=ax,legend = False)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7-X3bCBVMYfb"
      },
      "source": [
        "We observe there is no observious pattern in the residuals plot and the center of the density of residuals lies around zero."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "id": "j6lDY3cWRj8D",
        "outputId": "06c487b4-f981-43a2-d7dd-f6c823ef3bc9"
      },
      "outputs": [],
      "source": [
        "# Generate acf and pacf plot\n",
        "fig = plt.figure(tight_layout = True, figsize = (10, 4))\n",
        "gs = gridspec.GridSpec(1, 2)\n",
        "ax = fig.add_subplot(gs[0,0])\n",
        "plot_acf(residuals,ax = ax)\n",
        "ax = fig.add_subplot(gs[0,1])\n",
        "plot_pacf(residuals,ax = ax)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IscKpVzd8miY"
      },
      "source": [
        "The autocorrelation and partial autocorrelation plot suggest that there is no significant coefficient. Therefore, the model fitted to the data is adequate. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kL0sc1DjLvdm"
      },
      "source": [
        "### ARIMA forecasting\n",
        "With the determined orders $p,d,q$ and the fitting ARIMA model, we can then forecast the future."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sMF_2WKt9X_a"
      },
      "source": [
        "**Example**: Forecast the future trend based on the `model_fit` we derived in the previous example and check whether the forecasting is valid by comparing the forecasts and the `arima_array_test`. The function `.forecast` will be used and it will return three arrays: \n",
        "\n",
        "1. forecast array: array of out of sample forecasts. \n",
        "2. stderr array: array of the standard errorof the forecasts.  \n",
        "3. conf_int array: 2d array of the confidence interval for the forecasts."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "id": "iBbaJ_r0fU7-",
        "outputId": "bf1949b6-a273-46eb-b8d4-53a3f0432de7"
      },
      "outputs": [],
      "source": [
        "n_pred = 50 # Lead time, or forecasting horizon -- the number of steps ahead for out of sample forecast \n",
        "pred_array, se_array, CI_array = model.fit().forecast(steps=n_pred,alpha=0.05) # alpha: confidence level\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "pred_array_index = range(200,250)\n",
        "\n",
        "plt.figure(figsize=(12,4))\n",
        "plt.plot(my_arima_array)\n",
        "plt.plot(pred_array_index, pred_array, color = \"red\")\n",
        "plt.fill_between(pred_array_index, CI_array[:,0], CI_array[:,1], color = \"k\", alpha = .15 )\n",
        "plt.title('Forecast of the simulated data')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FdyTxgHR5STE"
      },
      "source": [
        "### The Box-Jenkins approach for time series forecasting\n",
        "* (1) *Model identification* \\\\\n",
        "Examine the data to see which member of the class of ARIMA processes appears to be most appropriate. Difference the data. Check the autocorrelation and partical autocorrelation. \n",
        "* (2) *Estimation* \\\\\n",
        "Estimate the parameters of the chosen model.\n",
        "* (3) *Diagnostic checking* \\\\\n",
        "Examine the residuals from the fitted model to see if there is evidence of non-randomness. \n",
        "* (4) *Consideration of alternative models if necessary*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0b0vXnLnLlMD"
      },
      "source": [
        "### Automatic determination of the orders of an ARIMA model\n",
        "The manually iterative fitting procedure is an art and requires experience. The function below searches over multiple combinations of $p,d,q$ parameters and choose the optimal ARIMA model that has the least value of the AIC criterion."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NTjPFbY4OrQH"
      },
      "outputs": [],
      "source": [
        "# Find the optimal ARIMA model that has the least value of the AIC criterion.\n",
        "# Return: (p, d, q) that minimizes AIC criterion.\n",
        "\n",
        "import itertools\n",
        "def arima_order(data, order=10, verbose=True):\n",
        "  p=d=q=range(0,order)\n",
        "  pdq = list(itertools.product(p,d,q))\n",
        "  warnings.filterwarnings(\"ignore\")\n",
        "  aic_pair={}\n",
        "  min_aic=9999999\n",
        "  min_order=(0,0,0)\n",
        "  for o in pdq:\n",
        "    try:\n",
        "      model_arima = ARIMA(data, order=o)\n",
        "      model_arima_fit=model_arima.fit()\n",
        "      fit_aic = model_arima_fit.aic\n",
        "      if verbose: print(o, \"AIC=\", fit_aic)\n",
        "      if not np.isnan(fit_aic):\n",
        "        if min_aic>fit_aic:\n",
        "          min_aic = fit_aic\n",
        "          min_order=o\n",
        "      aic_pair.update({o, rmodel_arima_fit.aic})\n",
        "    except:\n",
        "      continue\n",
        "  return min_order"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MlgJ8tvDm7jf",
        "outputId": "e0117533-baf7-47ee-a548-b98a70cd77af"
      },
      "outputs": [],
      "source": [
        "arima_order(my_arima_array_train, order=5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qqIyktvmkXQa"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.15 (main, Nov 24 2022, 08:28:41) \n[Clang 14.0.6 ]"
    },
    "vscode": {
      "interpreter": {
        "hash": "89f14702fcce0156c986c061756de7d507c7a3a57e942941020409f4fe24a6dc"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
